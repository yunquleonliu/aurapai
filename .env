# Auro-PAI Platform Backend Environment Configuration

# Basic Application Settings
APP_NAME=Auro-PAI Platform Backend
VERSION=1.0.0
DEBUG=false
HOST=0.0.0.0
PORT=8001

# CORS Settings (adjust for your frontend)
ALLOWED_ORIGINS=["http://localhost:3000", "http://localhost:8080", "http://localhost:8001", "http://127.0.0.1:3000"]

# LLM Settings - llama.cpp
LLAMACPP_SERVER_URL=http://10.0.0.206:8000
LLAMACPP_MODEL_NAME=mixtral-8x7b-instruct
LLAMACPP_TIMEOUT=600

# Alternative LLM Providers (optional)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4

# GEMINI_API_KEY=your_gemini_api_key_here
# GEMINI_MODEL=gemini-pro

# RAG Settings - ChromaDB
CHROMADB_HOST=localhost
CHROMADB_PORT=8002
CHROMADB_COLLECTION_NAME=auro_pai_knowledge

# Vector Embedding Settings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Tool Settings
WEB_SEARCH_ENABLED=true
WEB_SEARCH_ENGINE=duckduckgo
# WEB_SEARCH_API_KEY=your_search_api_key_here  # For Bing/Google if needed

URL_FETCH_TIMEOUT=30
URL_FETCH_MAX_SIZE=1048576  # 1MB

# Context Management
MAX_CONTEXT_LENGTH=8192
MAX_SESSIONS=100
SESSION_TIMEOUT=3600  # 1 hour

# File Processing
SUPPORTED_FILE_TYPES=[".py", ".js", ".ts", ".java", ".cpp", ".c", ".h", ".hpp", ".md", ".txt", ".json", ".yaml", ".yml", ".xml", ".html", ".css", ".sql", ".sh", ".bat", ".ps1"]

# Security (optional)
# API_KEY=your_api_key_here
RATE_LIMIT_PER_MINUTE=60

# Logging
LOG_LEVEL=INFO
# LOG_FILE=/var/log/auro-pai/backend.log

# Database (optional for persistence)
# DATABASE_URL=postgresql+asyncpg://username:password@localhost:5432/auropai
