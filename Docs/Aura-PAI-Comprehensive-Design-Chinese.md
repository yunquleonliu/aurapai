# Aura-PAI 综合设计文档

## 1. 概述
Aura-PAI 是一个符合隐私标准、功能强大且统一的对话式 AI 平台，支持 Web 和移动客户端。它使用 ChromaDB 提供持久化、可搜索的聊天历史记录，支持工具调用（包括图像生成/解读），并拥有响应式现代 UI。

### 1.1. 目标受众
- **非技术用户（“普通人”）:** 没有提示工程、软件开发或 AI 模型训练背景的个人。
- **注重隐私的用户:** 重视数据隐私并愿意为安全、本地优先的解决方案投入的用户。

### 1.2. 高级架构
后端采用模块化的分层架构，以 FastAPI 作为核心协调器，解耦了客户端接口、AI 逻辑、数据检索和外部工具交互。

```
+---------------------------+
|   客户端 (Web UI 等)      |
+---------------------------+
             |
             v
+---------------------------+
|    FastAPI 后端           |
| (Python 应用层)         |
+---------------------------+
| - API 端点                |
| - Agentic 循环            |
| - 上下文管理              |
+---------------------------+
      |          |        |
      v          v        v
+----------+ +-------+ +----------+
| LLM      | | RAG   | | 工具     |
| (本地/   | |(Chroma| | (Web,    |
| 公共)    | | DB)   | | 等)      |
+----------+ +-------+ +----------+
```

> **注意:** 后端 API 服务器默认在端口 **8001** 上运行。以下所有 API 端点均假定 `http://<host>:8001` 为基础 URL。

---

## 2. 核心架构挑战：有状态、多步骤对话
Aura-PAI 的主要目标是处理复杂的用户请求，这些请求需要多个步骤、工具使用和访问外部信息（例如，“查找有关纳斯达克的最新消息，总结要点，并告诉我現在是否是投资的好时机。”）。这需要一个能够管理状态、推理问题并执行计划的复杂 Agent 架构。

一个核心挑战是在个性化和隐私之间进行权衡。更个性化的 AI 需要记住用户上下文和历史记录，但这会引发隐私问题。Aura-PAI 的架构旨在通过让用户控制其数据及其使用方式来解决此问题。

---

## 3. 已实现特性与功能 (截至 2025 年 6 月)

### 3.1. 核心功能
- **本地 LLM 集成:** 与本地 `llama.cpp` 服务器（托管 LLaVA + Mixtral 等模型）无缝集成，并具有可扩展的设计以支持公共 LLM（OpenAI、Gemini）。
- **检索增强生成 (RAG):** 与 ChromaDB 集成，用于对本地代码库和文档进行索引和语义搜索。
- **多模态能力:** 支持图像生成（文本到图像）和图像解读（图像到文本）。
- **工具集成:** 原生支持 Web 搜索 (DuckDuckGo)、URL 获取和其他工具。
- **有状态对话管理:** 管理会话历史、上下文窗口和内存优化。

### 3.2. AI 能力与工具
平台支持通过基于 JSON 的工具调用协议编排的一系列 AI 功能：
- `search_and_fetch`: 执行 Web 搜索、获取内容并提供摘要。
- `image_generation`: 根据文本描述生成图像。
- `interpret_image`: 分析图像内容并提供文本描述。
- `web_search`: 进行实时 Web 搜索。
- `url_fetch`: 从给定 URL 获取并提取内容。

---

## 4. Agent 实现策略：功能标记驱动的演进
为在创新的同时确保稳定性，我们采用功能标记驱动的方法。应用程序支持两种不同的 Agent 架构，由 `core/config.py` 中的 `AGENT_MODE` 设置控制。

-   `AGENT_MODE = "Plan-and-Execute"`: (默认, 稳定) 使用原始、强大的 Agent，该 Agent 会预先创建完整计划并逐步执行。**此模式旨在与功能强大的公共 LLM（例如 Gemini）一起使用。**
-   `AGENT_MODE = "ReAct"`: (开发中) 使用下一代分层 Agent，该 Agent 在动态的、逐步的推理循环中结合了本地、注重隐私的 LLM 和强大的公共 LLM。**这是唯一适用于本地 LLM 的模式。**

此策略允许安全、并行地开发和测试新的 ReAct Agent，而不会干扰当前已部署且正常工作的 `Plan-and-Execute` Agent。

---

## 5. 架构 1：Plan-and-Execute Agent (用于公共 LLM)
这是当前用于处理多步骤任务的稳定架构，配合强大的公共 LLM 使用。

### 核心工作流
工作流包括三个主要阶段：分解（规划）、状态管理和执行。

#### a. 分解 (规划)
-   **目标:** 初始 LLM 调用以 JSON 格式创建完整的结构化计划。
-   **提示:** 指示 LLM 充当规划者，将用户请求分解为一系列工具调用。

#### b. 状态管理 (上下文管理器)
-   **目标:** 跟踪多步骤计划的进度。
-   **实现:** 在 `ConversationContext` 中存储一个 `MultiStepTask` 对象，以保存计划、当前步骤和每个操作的结果。

#### c. 执行循环 (编排器)
-   **目标:** 逐步执行计划。
-   **逻辑:** `api/routes/chat.py` 中的聊天端点遍历计划，通过 `tool_service.py` 调用必要的工具，并存储结果，直到计划完成。然后生成最终摘要。

---

## 6. 架构 2：分层 ReAct Agent (用于本地 LLM)
这是我们架构的下一次演进，旨在提高效率、适应性，并更清晰地分离私有和公共数据处理。这是**唯一**用于本地 LLM 的架构。

### 核心概念：分层 LLM 角色
此模型使用两种不同类型的 LLM：
-   **本地/私有 LLM (个人编排器):** 管理直接用户交互的本地模型。它在 **ReAct (推理-行动)** 框架上运行，在循环中决定下一个最佳行动。它可以访问私有的长期用户历史记录，并充当智能的、注重隐私的路由器。
-   **远程/公共 LLM (专家):** 一个强大的公共模型（例如 Gemini），被视为无状态的“工具”。它处理复杂的推理和知识密集型任务，仅接收来自本地编排器的经过策划的、特定上下文的提示。

### 核心循环：思考 -> 行动 -> 观察
本地 LLM 不采用严格的前期计划，而是参与一个动态循环：
1.  **思考 (推理):** 决定下一个最佳行动（例如，“我需要搜索网络以查找评论”）。
2.  **行动 (执行):** 执行该行动（例如，调用 `web_search` 工具或调用远程 LLM 工具）。
3.  **观察 (获取结果):** 接收结果并将其作为“观察”添加到上下文中。
4.  **重复:** 循环继续，直到本地 LLM 确定它有足够的信息来提供最终答案。

### 意图驱动的工具调用 (强大的 ReAct 设计)
**动机:** 本地 LLM 在生成格式完美的工具调用 JSON 方面通常不可靠。为了最大化可靠性，后端应根据 LLM 解释的意图处理确定性、准确和有状态的工具调用，而不是原始的 LLM 生成的工具调用代码。

**工作原理:**
-   本地 LLM 的工作是识别用户的意图和要使用的工具（例如，`{"tool": "generate_image", "intent": "a picture of a chicken"}`）。
-   后端解析此意图，验证并填写所需参数，并构造正确的工具调用。
-   这种方法更可靠，更易于调试，也更安全，尤其是在使用本地 LLM 时。

---

## 7. 核心工作流

### 7.1. 查询-意图-路由-输出工作流
此工作流确保用户查询得到一致且可预测的处理。

1.  **意图检测:** 后端使用 LLM 对用户查询的意图进行分类（例如，`image_generation`、`web_search`、`text_generation`）。
2.  **严格路由:** 根据检测到的意图将请求路由到适当的服务。没有“失败后备”逻辑；生成图像的请求将仅转到图像生成服务。
3.  **绑定输出:** 输出类型与意图严格绑定。图像生成请求返回图像，文本生成请求返回文本。

### 7.2. 互联网增强的 RAG 工作流
此工作流允许 LLM 在闭环中通过工具访问外部信息。

1.  **工具调用提示:** 提示 LLM 生成一个 JSON 对象，指定工具和参数（例如，`{"action": "search_and_fetch", "query": "latest AI news"}`）。
2.  **后端执行:** 后端解析 JSON 并执行指定的工具。
3.  **结果注入和摘要:** 工具的输出被注入回 LLM 的上下文，并再次提示 LLM 为用户生成最终的摘要答案。

---

## 8. 数据管理与隐私

### 8.1. 聊天历史存储
- **统一存储:** 所有聊天历史记录都存储在专用的 **ChromaDB** 集合中，与 RAG 知识库分开。
- **数据模型:** 每条消息都是一个包含会话 ID、时间戳、内容和类型（用户、助手、图像等）的文档。
- **隐私优先:** 数据默认存储在本地。用户有权随时查看、导出和删除其历史记录。

### 8.2. 前端历史管理
- **响应式 UI:** UI 在桌面上使用并排布局（会话列表 + 聊天视图），在移动设备上使用选项卡式布局。
- **功能:** 用户可以按关键字搜索历史记录，按日期筛选，以及删除或导出整个会话。

---

## 9. 前端与多设备集成
- **Web 前端:** 一个完全实现的 Web 客户端，支持文本聊天、图像上传和渲染生成的图像。
- **移动/其他客户端 (计划中):** 后端 API 旨在供未来的客户端使用，包括原生 Android/iOS 应用和 VS Code 扩展。

---

## 10. API 端点 (摘要)
- `POST /api/v1/chat` — 主聊天端点（文本、工具或图像输入）。支持 ReAct (本地 LLM) 和 Plan-and-Execute (公共 LLM) 模式，自动路由。
- `POST /api/v1/tools/interpret-image` — 图像上传/分析
- `POST /api/v1/chat/generate-image` — 根据提示生成图像
- `GET /api/v1/chat/history` — 列出/搜索聊天历史记录（带关键字、session_id）
- `DELETE /api/v1/chat/history` — 删除全部或按会话删除历史记录
- `GET /api/v1/chat/history/export` — 导出回话历史
- `GET /api/v1/tools` — 列出可用的工具和模式

---

## 11. 已知问题与后续步骤
- **通过自然语言意图进行工具调用正在进行中。** 系统目前依赖于更明确的工具调用格式。
- **增强多工具协作和错误处理。** 提高 Agent 对多个工具进行排序和从故障中恢复的能力。
- **改进 API 文档和测试覆盖率。**
- **确保 Plan-and-Execute Agent 逻辑仅用于公共 LLM，而 ReAct 是本地 LLM 的唯一模式。** 根据需要更新代码和文档。

---

## 12. 贡献者
- 后端: [Yunqu Leon Liu yunqu.liu@gmail.lcom]
- 前端: [Yunqu Leon Liu yunqu.liu@gmail.com]
- 设计/文档: [Yunqu Leon Liu yunqu.liu@gmail.com]

---

_最后更新: 2025-07-01_
